{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASE 2: Árboles de decisión, métricas de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Census Income Data Set: http://mlr.cs.umass.edu/ml/datasets/Census+Income\n",
    "\n",
    "Abstract: Predict whether income exceeds $50K/yr based on census data. Also known as \"Adult\" dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **age:** continuous.\n",
    "* **workclass:** Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "* **fnlwgt:** continuous.\n",
    "* **education:** Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "* **education-num:** continuous.\n",
    "* **marital-status:** Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "* **occupation:** Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "* **relationship:** Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "* **race:** White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "* **sex:** Female, Male.\n",
    "* **capital-gain:** continuous.\n",
    "* **capital-loss:** continuous.\n",
    "* **hours-per-week:** continuous.\n",
    "* **native-country:** United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32561, 15), (16281, 15))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_csv('data/census_train.csv')\n",
    "df_test = pd.read_csv('data/census_test.csv')\n",
    "df_raw.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "\n",
       "        marital-status          occupation    relationship    race    sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White   Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White   Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White   Male   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country   label  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9th</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Doctorate</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>5th-6th</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1st-4th</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Preschool</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>12th</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         education  education-num\n",
       "0        Bachelors             13\n",
       "2          HS-grad              9\n",
       "3             11th              7\n",
       "5          Masters             14\n",
       "6              9th              5\n",
       "10    Some-college             10\n",
       "13      Assoc-acdm             12\n",
       "14       Assoc-voc             11\n",
       "15         7th-8th              4\n",
       "20       Doctorate             16\n",
       "52     Prof-school             15\n",
       "56         5th-6th              3\n",
       "77            10th              6\n",
       "160        1st-4th              2\n",
       "224      Preschool              1\n",
       "415           12th              8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La variable \"education-num\" contiene la misma informacion que \"education\",\n",
    "# en tipo numérica y ordenada, por lo que borraremos \"education\"\n",
    "# pero guardaremos sus código en \"cat_dict\".\n",
    "education_codes = df_raw[['education', 'education-num']].drop_duplicates()\n",
    "education_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'education': {13: ' Bachelors',\n",
       "  9: ' HS-grad',\n",
       "  7: ' 11th',\n",
       "  14: ' Masters',\n",
       "  5: ' 9th',\n",
       "  10: ' Some-college',\n",
       "  12: ' Assoc-acdm',\n",
       "  11: ' Assoc-voc',\n",
       "  4: ' 7th-8th',\n",
       "  16: ' Doctorate',\n",
       "  15: ' Prof-school',\n",
       "  3: ' 5th-6th',\n",
       "  6: ' 10th',\n",
       "  2: ' 1st-4th',\n",
       "  1: ' Preschool',\n",
       "  8: ' 12th'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dict = education_codes.set_index('education-num').to_dict()\n",
    "cat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt  education       marital-status  \\\n",
       "0   39          State-gov   77516         13        Never-married   \n",
       "1   50   Self-emp-not-inc   83311         13   Married-civ-spouse   \n",
       "2   38            Private  215646          9             Divorced   \n",
       "\n",
       "           occupation    relationship    race    sex  capital-gain  \\\n",
       "0        Adm-clerical   Not-in-family   White   Male          2174   \n",
       "1     Exec-managerial         Husband   White   Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White   Male             0   \n",
       "\n",
       "   capital-loss  hours-per-week  native-country   label  \n",
       "0             0              40   United-States   <=50K  \n",
       "1             0              13   United-States   <=50K  \n",
       "2             0              40   United-States   <=50K  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Borramos \"education\" y cambiamos el nombre de \"education-num\" a \"education\"\n",
    "\n",
    "# Este estilo de escribir métodos de pandas, seguidos uno de otro, se llama method chaining\n",
    "df_raw = (df_raw.drop('education', axis=1)\n",
    "                .rename({'education-num': 'education'}, axis=1))\n",
    "          \n",
    "df_raw.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Preprocesar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-7-48f6704ff886>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-48f6704ff886>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    df_raw.dtypes\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# 1. Convertir las columnas a tipo \"category\", ignorar la variable dependiente\n",
    "for n,col in df_raw.items():\n",
    "    # COMPLETAR\n",
    "        \n",
    "df_raw.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. El dataset no tiene data faltante, por que vamos directo a trasnformar\n",
    "#    las columnas categóricas a numéricas.\n",
    "df = df_raw.copy()\n",
    "\n",
    "# Convertir cada columna categórica a numérica\n",
    "# COMPLETAR\n",
    "        \n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Train-validation split\n",
    "\n",
    "# COMPLETAR\n",
    "\n",
    "print(f'Train shape     : {x_train.shape}')\n",
    "print(f'Validation shape: {x_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenando un Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-0b9eed5fb4e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "m = RandomForestClassifier(n_estimators=10, n_jobs=-1)\n",
    "m.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a definir una función para ver los resultados del entrenamiento.\n",
    "def score():\n",
    "    print(f'Scores:')\n",
    "    print(f'Train      = {m.score(x_train, y_train):.4}')\n",
    "    print(f'Validation = {m.score(x_val, y_val):.4}')\n",
    "    \n",
    "score()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# El parámetro \"estimators_\" del modelo, contiene los árboles entrenados.\n",
    "# Vamos a obtener las prediciones de cada árbol\n",
    "preds = np.stack([t.predict(x_val) for t in m.estimators_])\n",
    "print(preds.shape)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos el score de cada árbol\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accs = [accuracy_score(y_val==' >50K', p) for p in preds]\n",
    "plt.plot(accs, '-o')\n",
    "plt.title('Scores invididuales');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora veamos el score acumulado\n",
    "acum_accs = [accuracy_score(y_val==' >50K', np.mean(preds[:i+1,:], axis=0) > 0.5) for i in range(len(preds))]\n",
    "plt.plot(acum_accs, '-o')\n",
    "plt.title('Scores acumulados');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usemos los árboles para obtener una predicción con una estimación de confianza.\n",
    "sample = x_val.sample(1)\n",
    "\n",
    "pred = np.stack([t.predict(sample) for t in m.estimators_])\n",
    "\n",
    "pred.mean() > 0.5, pred.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-bag (OOB) score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Nuestra validación es peor en el conjunto de validación debido a overfitting, o es porque el conjunto de validación es para un período de tiempo diferente, o un poco de ambos?\n",
    "\n",
    "Con la información existente que hemos mostrado, no podemos decirlo. Sin embargo, los bosques aleatorios tienen un truco muy ingenioso: oobs core (error fuera de la bolsa).\n",
    "\n",
    "La idea es calcular el error en el conjunto de entrenamiento, donde la predicción de cada elemento se haga sólo por los árboles que no lo incluyeron en su entrenamiento. Esto nos permite ver si el modelo se ajusta demasiado, sin necesidad de un conjunto de validación por separado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestClassifier(n_estimators=40, n_jobs=-1, oob_score=True)\n",
    "m.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a modificar la función score, para incluir el oob score.\n",
    "def score():\n",
    "    print(f'Scores:')\n",
    "    print(f'Train      = {m.score(x_train, y_train):.4}')\n",
    "    print(f'Validation = {m.score(x_val, y_val):.4}')\n",
    "    if hasattr(m, 'oob_score_'): print(f'OOB        = {m.oob_score_:.4}')\n",
    "    \n",
    "score()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algunos paŕametros importantes al crear un Random Forest:**\n",
    "* n_estimators: cantidad de árboles\n",
    "* max_depth: la máxima profundidad de cada árbol\n",
    "* min_samples_leaf: cantidad de muestras mínimas para que puede tener una rama.\n",
    "* max_features: cantidad de columnas que ve cada árbol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "House Sales Prediction Data Set: https://www.kaggle.com/harlfoxem/housesalesprediction/home\n",
    "\n",
    "Abstract: This dataset contains house sale prices for King County, which includes Seattle. It includes homes sold between May 2014 and May 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **id**: a notation for a house\n",
    "- **date**: Date house was sold\n",
    "- **price**: Price is prediction target\n",
    "- **bedrooms**: Number of Bedrooms/House\n",
    "- **bathrooms**: Number of bathrooms/bedrooms\n",
    "- **sqft_living**: square footage of the home\n",
    "- **sqft_lot**: square footage of the lot\n",
    "- **floors**: Total floors (levels) in house\n",
    "- **waterfront**: House which has a view to a waterfront\n",
    "- **view**: Has been viewed\n",
    "- **condition**: How good the condition is ( Overall )\n",
    "- **grade**: overall grade given to the housing unit, based on King County grading system\n",
    "- **sqft_above**: square footage of house apart from basement\n",
    "- **sqft_basement**: square footage of the basement\n",
    "- **yr_built**: Built Year\n",
    "- **yr_renovated**: Year when house was renovated\n",
    "- **zipcode**: zip\n",
    "- **lat**: Latitude coordinate\n",
    "- **long**: Longitude coordinate\n",
    "- **sqft_living15**: Living room area in 2015(implies-- some renovations) This might or might not have affected the lotsize area\n",
    "- **sqft_lot15**: lotSize area in 2015(implies-- some renovations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('data/kc_house_data.csv', parse_dates=['date'])\n",
    "print(df_raw.shape)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borramos la variable \"id\"\n",
    "df_raw.drop('id', axis=1, inplace=True)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,3))\n",
    "sns.distplot(df_raw.price);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,3))\n",
    "sns.distplot(np.log(df_raw.price));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante tener en cuenta lo que estamos evaluando, en el caso de precios es bastante común tener mayor interes en el ratio del error que en el valor del error.\n",
    "\n",
    "* La predicción fallo en S/.10 vs la predicción fallo en 10%.\n",
    "* Un error de S/.100 en un precio de S/.1,000,000 vs un error de S/.100 en un precio de S/.1000.\n",
    "\n",
    "Por eso vamos a considerar el **log** del precio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.price = np.log(df_raw.price)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.date.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos usar \"dt\" para acceder a los métodos de fechas.\n",
    "df_raw.date.dt.year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si queremos acceder al atributo \"year\" desde una variable string usamos \"getattr()\"\n",
    "getattr(df_raw.date.dt, \"year\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Vamos a extrarer los parámetros útiles que se pueden extraer de fechas\n",
    "date_attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear', 'Is_month_end',\n",
    "             'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n",
    "\n",
    "for n in date_attr:\n",
    "    df_raw['date_' + n] = getattr(df_raw['date'].dt, n.lower())\n",
    "\n",
    "# 2. Agregamos una columan con una representación numérica de la fecha\n",
    "df_raw['date_elapsed'] = df_raw['date'].astype(np.int64) // 10 ** 9\n",
    "\n",
    "\n",
    "# 3. Eliminamos la variable date\n",
    "df_raw.drop('date', axis=1, inplace=True)\n",
    "\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos la cantidad de valores únicos de las variables que hemos creado\n",
    "df_raw[['date_'+e for e in date_attr]].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a eliminar \"date_Is_year_start\" dado que tiene el mismo valor para todo el dataset\n",
    "df_raw.drop('date_Is_year_start', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_raw.drop('price', axis=1)\n",
    "y = df_raw['price']\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "print(f'Train shape     : {x_train.shape}')\n",
    "print(f'Validation shape: {x_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar un árbol de regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "m = DecisionTreeRegressor(max_depth=2)\n",
    "m.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m.score retorna el coeficiente de determinación de la predicción\n",
    "score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veamos el mse\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_train, m.predict(x_train)), mean_squared_error(y_val, m.predict(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.draw_tree(m, x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculando los valores del árbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((y_train - y_train.mean())**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[x_train['grade'] <= 8.5].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((y_train[x_train['grade'] <= 8.5] - y_train[x_train['grade'] <= 8.5].mean())**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[x_train['grade'] > 8.5].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((y_train[x_train['grade'] > 8.5] - y_train[x_train['grade'] > 8.5].mean())**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando un random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "m = RandomForestRegressor(40, n_jobs=-1, oob_score=True)\n",
    "m.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn feature importance (mean decrease impurity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imp = pd.DataFrame({'cols':x_train.columns, 'imp':m.feature_importances_}).sort_values('imp', ascending=False)\n",
    "imp.style.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from rfpimp import importances, plot_importances\n",
    "\n",
    "imp = importances(m, x_val, y_val)\n",
    "plot_importances(imp, figsize=(5,9));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Drop-column importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from rfpimp import dropcol_importances\n",
    "\n",
    "imp = dropcol_importances(m, x_train, y_train)\n",
    "plot_importances(imp, figsize=(5,9));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Dependence Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **id**: a notation for a house\n",
    "- **date**: Date house was sold\n",
    "- **price**: Price is prediction target\n",
    "- **bedrooms**: Number of Bedrooms/House\n",
    "- **bathrooms**: Number of bathrooms/bedrooms\n",
    "- **sqft_living**: square footage of the home\n",
    "- **sqft_lot**: square footage of the lot\n",
    "- **floors**: Total floors (levels) in house\n",
    "- **waterfront**: House which has a view to a waterfront\n",
    "- **view**: Has been viewed\n",
    "- **condition**: How good the condition is ( Overall )\n",
    "- **grade**: overall grade given to the housing unit, based on King County grading system\n",
    "- **sqft_above**: square footage of house apart from basement\n",
    "- **sqft_basement**: square footage of the basement\n",
    "- **yr_built**: Built Year\n",
    "- **yr_renovated**: Year when house was renovated\n",
    "- **zipcode**: zip\n",
    "- **lat**: Latitude coordinate\n",
    "- **long**: Longitude coordinate\n",
    "- **sqft_living15**: Living room area in 2015(implies-- some renovations) This might or might not have affected the lotsize area\n",
    "- **sqft_lot15**: lotSize area in 2015(implies-- some renovations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdpbox import pdp, info_plots\n",
    "\n",
    "df_train = x_train.assign(price=y_train)\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examinemos la variable \"yr_built\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos como se distribuye en la data que tenemos, con respecto a nuestro target\n",
    "info_plots.target_plot(df_train, 'yr_built', 'Year built', 'price');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora veamos como reacciona el modelo a esta variable\n",
    "pdp_year_built = pdp.pdp_isolate(m, x_train, x_train.columns, 'yr_built')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pdp.pdp_plot(pdp_year_built, 'Year built', plot_lines=True, frac_to_plot=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos la opción de clusters para agrupar mejor los comportamientos\n",
    "fig, axes = pdp.pdp_plot(pdp_year_built, 'Year built', cluster=True, n_cluster_centers=5)\n",
    "axes['pdp_ax'].set_ylim(-0.45,0.2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Veamos las interacciones entre longitud y latitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp_lat_long = pdp.pdp_interact(m, x_train, x_train.columns, ['long', 'lat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp.pdp_interact_plot(pdp_lat_long, ['long', 'lat'], plot_pdp=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from treeinterpreter import treeinterpreter as ti\n",
    "\n",
    "sample = x_val.sample()\n",
    "print(f'Real price = {y_val[sample.index[0]]}')\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, bias, contributions = ti.predict(m, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción final\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias inicial\n",
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contribuciones de cada variable\n",
    "contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos las contribuciones con el nombre de las variables\n",
    "tt = pd.DataFrame(contributions, columns=sample.columns).T.sort_values(0)\n",
    "tt.style.background_gradient(cmap='YlOrRd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos un waterfallplot para tener una mejor visualización de la predicción\n",
    "utils.waterfallplot(sample, contributions[0], formatting='{:,.3f}', size=(13,6), sorted_value=True, threshold=0.05);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Utilizar los métodos de interpretación en el Census Income Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **age:** continuous.\n",
    "* **workclass:** Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "* **fnlwgt:** continuous.\n",
    "* **education:** Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "* **education-num:** continuous.\n",
    "* **marital-status:** Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "* **occupation:** Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "* **relationship:** Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "* **race:** White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "* **sex:** Female, Male.\n",
    "* **capital-gain:** continuous.\n",
    "* **capital-loss:** continuous.\n",
    "* **hours-per-week:** continuous.\n",
    "* **native-country:** United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revisitando Train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar la data del ejemplo de regresión\n",
    "df = df_raw.sort_values('date_elapsed')\n",
    "x = df.drop('price', axis=1)\n",
    "y = df['price']\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, shuffle=False)\n",
    "print(f'Train shape     : {x_train.shape}')\n",
    "print(f'Validation shape: {x_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(40, n_jobs=-1, oob_score=True)\n",
    "m.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Last score**:\n",
    "\n",
    "* Train score      = 0.9833\n",
    "* Validation score = 0.8884\n",
    "* OOB score        = 0.879"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debilidades de Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(100)/100\n",
    "y = x + np.random.normal(scale=0.05, size=100)\n",
    "\n",
    "plt.scatter(x, y, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.4, shuffle=False)\n",
    "plt.scatter(x_train, y_train, alpha=0.5)\n",
    "plt.scatter(x_val, y_val, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para poder entrenar la data, esta tiene que tener 2 dimensiones\n",
    "x_train[:, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[:, None]\n",
    "x_val = x_val[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(40, oob_score=True)\n",
    "m.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinemos los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = m.predict(x_train)\n",
    "pred_val = m.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_train, pred_train, alpha=0.5)\n",
    "plt.scatter(x_val, pred_val, alpha=0.5);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "300.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
